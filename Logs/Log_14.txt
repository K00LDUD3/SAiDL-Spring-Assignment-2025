2025-02-06 17:00:21 - <bound method Module.state_dict of NormalizedCrossEntropyLoss_REVISED(
  (reduction): SimpleCNN(
    (conv_layers): Sequential(
      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU()
      (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (7): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (8): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (9): ReLU()
      (10): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (11): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (12): ReLU()
      (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (14): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (15): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (16): ReLU()
      (17): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (18): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (19): ReLU()
      (20): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    (fc_layers): Sequential(
      (0): Flatten(start_dim=1, end_dim=-1)
      (1): Linear(in_features=2048, out_features=256, bias=True)
      (2): ReLU()
      (3): Dropout(p=0.5, inplace=False)
      (4): Linear(in_features=256, out_features=10, bias=True)
    )
  )
  (cross_entropy): CrossEntropyLoss()
)>
2025-02-06 17:00:21 - 

2025-02-06 17:00:21 - <bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    differentiable: False
    foreach: None
    fused: None
    initial_lr: 0.01
    lr: 0.01
    maximize: False
    momentum: 0.9
    nesterov: False
    weight_decay: 0.001
)>
2025-02-06 17:00:21 - 

2025-02-06 17:00:21 - {'step_size': 10, 'gamma': 0.5, 'base_lrs': [0.01], 'last_epoch': 0, 'verbose': False, '_step_count': 1, '_get_lr_called_within_step': False, '_last_lr': [0.01]}
2025-02-06 17:00:21 - 

2025-02-06 17:00:21 - Termination Train Loop (Manual)
2025-02-06 17:02:24 - <bound method Module.state_dict of NormalizedCrossEntropyLoss_REVISED(
  (reduction): SimpleCNN(
    (conv_layers): Sequential(
      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU()
      (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (7): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (8): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (9): ReLU()
      (10): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (11): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (12): ReLU()
      (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (14): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (15): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (16): ReLU()
      (17): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (18): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (19): ReLU()
      (20): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    (fc_layers): Sequential(
      (0): Flatten(start_dim=1, end_dim=-1)
      (1): Linear(in_features=2048, out_features=256, bias=True)
      (2): ReLU()
      (3): Dropout(p=0.5, inplace=False)
      (4): Linear(in_features=256, out_features=10, bias=True)
    )
  )
  (cross_entropy): CrossEntropyLoss()
)>
2025-02-06 17:02:24 - 

2025-02-06 17:02:24 - <bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    differentiable: False
    foreach: None
    fused: None
    initial_lr: 0.01
    lr: 0.01
    maximize: False
    momentum: 0.9
    nesterov: False
    weight_decay: 0.001
)>
2025-02-06 17:02:24 - 

2025-02-06 17:02:24 - {'step_size': 10, 'gamma': 0.5, 'base_lrs': [0.01], 'last_epoch': 0, 'verbose': False, '_step_count': 1, '_get_lr_called_within_step': False, '_last_lr': [0.01]}
2025-02-06 17:02:24 - 

2025-02-06 17:02:48 - Epoch 1/100 | Train Loss: 0.9514, Train Accuracy: 0.2709 | Test Loss: 0.8387, Test Accuracy: 0.4757
2025-02-06 17:03:12 - Epoch 2/100 | Train Loss: 0.9199, Train Accuracy: 0.3474 | Test Loss: 0.8125, Test Accuracy: 0.5234
2025-02-06 17:03:37 - Epoch 3/100 | Train Loss: 0.9061, Train Accuracy: 0.3809 | Test Loss: 0.7994, Test Accuracy: 0.5443
2025-02-06 17:04:02 - Epoch 4/100 | Train Loss: 0.8963, Train Accuracy: 0.4059 | Test Loss: 0.7789, Test Accuracy: 0.5681
2025-02-06 17:04:26 - Epoch 5/100 | Train Loss: 0.8877, Train Accuracy: 0.4249 | Test Loss: 0.7664, Test Accuracy: 0.6076
2025-02-06 17:04:51 - Epoch 6/100 | Train Loss: 0.8805, Train Accuracy: 0.4416 | Test Loss: 0.7543, Test Accuracy: 0.6423
2025-02-06 17:05:16 - Epoch 7/100 | Train Loss: 0.8738, Train Accuracy: 0.4561 | Test Loss: 0.7498, Test Accuracy: 0.6447
2025-02-06 17:05:41 - Epoch 8/100 | Train Loss: 0.8687, Train Accuracy: 0.4665 | Test Loss: 0.7425, Test Accuracy: 0.6682
2025-02-06 17:06:06 - Epoch 9/100 | Train Loss: 0.8629, Train Accuracy: 0.4780 | Test Loss: 0.7237, Test Accuracy: 0.6894
2025-02-06 17:06:30 - Epoch 10/100 | Train Loss: 0.8606, Train Accuracy: 0.4855 | Test Loss: 0.7351, Test Accuracy: 0.6589
2025-02-06 17:06:55 - Epoch 11/100 | Train Loss: 0.8499, Train Accuracy: 0.5002 | Test Loss: 0.7040, Test Accuracy: 0.6966
2025-02-06 17:07:20 - Epoch 12/100 | Train Loss: 0.8456, Train Accuracy: 0.5095 | Test Loss: 0.7029, Test Accuracy: 0.6994
2025-02-06 17:07:45 - Epoch 13/100 | Train Loss: 0.8444, Train Accuracy: 0.5117 | Test Loss: 0.6997, Test Accuracy: 0.7195
2025-02-06 17:08:09 - Epoch 14/100 | Train Loss: 0.8415, Train Accuracy: 0.5141 | Test Loss: 0.7076, Test Accuracy: 0.7117
2025-02-06 17:08:34 - Epoch 15/100 | Train Loss: 0.8397, Train Accuracy: 0.5220 | Test Loss: 0.7017, Test Accuracy: 0.6942
2025-02-06 17:08:59 - Epoch 16/100 | Train Loss: 0.8381, Train Accuracy: 0.5218 | Test Loss: 0.6924, Test Accuracy: 0.7246
2025-02-06 17:09:24 - Epoch 17/100 | Train Loss: 0.8361, Train Accuracy: 0.5250 | Test Loss: 0.6824, Test Accuracy: 0.7278
2025-02-06 17:09:48 - Epoch 18/100 | Train Loss: 0.8341, Train Accuracy: 0.5287 | Test Loss: 0.6900, Test Accuracy: 0.7291
2025-02-06 17:10:13 - Epoch 19/100 | Train Loss: 0.8319, Train Accuracy: 0.5336 | Test Loss: 0.6846, Test Accuracy: 0.7199
2025-02-06 17:10:38 - Epoch 20/100 | Train Loss: 0.8299, Train Accuracy: 0.5342 | Test Loss: 0.6781, Test Accuracy: 0.7403
2025-02-06 17:11:02 - Epoch 21/100 | Train Loss: 0.8237, Train Accuracy: 0.5439 | Test Loss: 0.6713, Test Accuracy: 0.7497
2025-02-06 17:11:27 - Epoch 22/100 | Train Loss: 0.8218, Train Accuracy: 0.5481 | Test Loss: 0.6672, Test Accuracy: 0.7418
2025-02-06 17:11:51 - Epoch 23/100 | Train Loss: 0.8198, Train Accuracy: 0.5497 | Test Loss: 0.6719, Test Accuracy: 0.7535
2025-02-06 17:12:16 - Epoch 24/100 | Train Loss: 0.8185, Train Accuracy: 0.5506 | Test Loss: 0.6732, Test Accuracy: 0.7488
