{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "078a4c59-ec13-43e1-8f4e-a0f470b9770b",
   "metadata": {},
   "source": [
    "## Import Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "3e8a38fc-2aca-4116-9e4a-1572d7b04516",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('cuda', '2.5.1+cu118')"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.datasets import CIFAR10\n",
    "\n",
    "# from torchmetrics import \n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from LogTracker import IntegerTracker\n",
    "\n",
    "import copy\n",
    "import math\n",
    "import time \n",
    "\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "DEVICE, torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "1b5c0ab8-dcef-4f1c-9afb-4f65ad1d2f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOWER, UPPER = 0.2, 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "b32755da-3d16-40cb-ba6e-55042403e6e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x28d0fe7ac70>"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(24)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c335cff0-92c4-42e1-a952-1ed67a714370",
   "metadata": {},
   "source": [
    "## Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "649af436-0e44-4947-8d7e-faa84a76eeaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform_v1 = transforms.Compose([ ### VER 1\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "transform_v2 = transforms.Compose([ ###VER 2\n",
    "    transforms.RandomCrop(32, padding=4),  # Randomly crop with padding\n",
    "    transforms.RandomHorizontalFlip(p=0.5),  # Flip images with 50% probability\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),  # Color Augmentation\n",
    "    transforms.RandomRotation(15),  # Rotate by ±15 degrees\n",
    "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),  # Random shifting\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "    transforms.RandomErasing(p=0.2)  # Randomly erase parts of the image\n",
    "])\n",
    "\n",
    "transform = transforms.Compose([ ###VER 3\n",
    "    transforms.RandomHorizontalFlip(p=0.5),  # 50% chance of mirroring\n",
    "    transforms.RandomRotation(10),  # Rotate by ±10 degrees\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "train_dataset = CIFAR10(root='data', download=True ,transform=transform, train=True)\n",
    "test_dataset = CIFAR10(root='data', download=True ,transform=transform, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "a0ec9534-d24a-4193-ae66-ef6738a3489d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "5a97059f-14b6-431e-bdc7-aedded602841",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.0..0.99215686].\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(32, 32, 3)"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img, lab = train_dataset[1]\n",
    "img= img.numpy().transpose((1, 2, 0))\n",
    "plt.imshow(img)\n",
    "plt.title(lab)\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "25b18171-84f0-47eb-afc2-3f02b5e46c1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes = len(train_dataset.classes)\n",
    "num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "11e1a60c-60d0-49ce-8e00-eedd27194393",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mask Info...\n",
      "\tExpected Noise Rate: 0.494 | Actual Noise Rate:  0.494 | Samples : 50000\n"
     ]
    }
   ],
   "source": [
    "def NoiseLabels(dataset : CIFAR10, lower=LOWER, upper=UPPER, noise_rate=None):\n",
    "    if noise_rate == None:\n",
    "        noise_rate = random.uniform(lower, upper)\n",
    "    \n",
    "    targets = np.array(dataset.targets)\n",
    "    n_samples = len(targets)\n",
    "    \n",
    "    noise_bools = np.random.rand(n_samples) < noise_rate\n",
    "    true_vals = np.sum(noise_bools)\n",
    "\n",
    "    #\n",
    "    print(f\"Mask Info...\\n\\tExpected Noise Rate: {noise_rate:.3f} | Actual Noise Rate: {true_vals/len(noise_bools) : .3f} | Samples : {(len(noise_bools))}\")\n",
    "\n",
    "    for i in range(len(noise_bools)):\n",
    "        if not noise_bools[i]:\n",
    "            continue\n",
    "\n",
    "        original_label = targets[i]\n",
    "\n",
    "        def RandomLabel():\n",
    "            random_label = np.random.choice(targets)\n",
    "            return random_label if random_label != original_label else RandomLabel()\n",
    "        new_label = RandomLabel()\n",
    "        targets[i] = new_label\n",
    "    dataset.targets = targets.tolist()\n",
    "    return dataset\n",
    "# train_data = datasets.CIFAR10(root='data', download=True, train=True, transform=transform)\n",
    "train_data_noise = NoiseLabels(copy.deepcopy(train_dataset))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aecc64b-d0f9-46a6-8b70-28010e0ae7f2",
   "metadata": {},
   "source": [
    "## Noisy Dataset - Inherited Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "23d90bba-276c-48fd-b638-edb3ee3ce4cc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Mask Info...\n",
      "\tExpected Noise Rate: 0.300 | Actual Noise Rate:  0.301 | True/False : 0.430\n"
     ]
    }
   ],
   "source": [
    "class NoisyDataset(CIFAR10):\n",
    "    def __init__(self, root='data', transform=None, train=True, download=True, lower=LOWER, upper=UPPER):\n",
    "            \n",
    "        super().__init__(root=root, train=train, transform=transform, download=download)\n",
    "        self.noise_rate = 0.2 + (0.8 - 0.2) * torch.rand(1).item()\n",
    "        self.noise_rate = 0.3\n",
    "        # print(f\"Randomly chosen noise rate: {self.noise_rate}\")\n",
    "        # self.classes = len(self.classes)\n",
    "        self.__Corrupt()\n",
    "\n",
    "    def __Corrupt(self):\n",
    "        targets = torch.tensor(self.targets)\n",
    "\n",
    "        n_samples = targets.size(0)\n",
    "        \n",
    "        noise_bools = torch.rand(n_samples) < self.noise_rate\n",
    "        \n",
    "        #\n",
    "        true_vals = noise_bools.sum().item()\n",
    "        print(f\"Mask Info...\\n\\tExpected Noise Rate: {self.noise_rate:.3f} | Actual Noise Rate: {true_vals/len(noise_bools) : .3f} | True/False : {true_vals/(len(noise_bools) - true_vals) :.3f}\")\n",
    "        \n",
    "        for i in range(len(noise_bools)):\n",
    "            if not noise_bools[i]:\n",
    "                continue\n",
    "            \n",
    "            original_label = targets[i]\n",
    "            new_label = self.__ChooseRandomLabel(original_label, targets)\n",
    "            targets[i] = new_label\n",
    "            \n",
    "        self.targets = targets.tolist()\n",
    "\n",
    "    @staticmethod\n",
    "    def __ChooseRandomLabel(original_label, targets):\n",
    "        possible_labels = list(range(num_classes))\n",
    "        possible_labels.remove(original_label)\n",
    "        new_label = possible_labels[torch.randint(0, len(possible_labels), (1,)).item()]\n",
    "        return new_label\n",
    "train_data_noise = NoisyDataset(root='data', train=True, transform=transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7879f311-af04-4044-a955-e109df2a401b",
   "metadata": {},
   "source": [
    "## Normalized Cross Entropy - V1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "064b0cd3-8d29-4be9-8c75-aab3f3d4a955",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NormalizedCrossEntropyLoss(nn.Module):\n",
    "    def __init__(self, reduction='mean'):\n",
    "        super(NormalizedCrossEntropyLoss, self).__init__()\n",
    "        self.reduction = reduction\n",
    "        self.cross_entropy = nn.CrossEntropyLoss(reduction='none')\n",
    "\n",
    "    def forward(self, logits, targets):\n",
    "        # Compute standard cross-entropy loss\n",
    "        ce_loss = self.cross_entropy(logits, targets)\n",
    "        \n",
    "        # Compute the entropy of the target distribution\n",
    "        target_probs = torch.softmax(logits, dim=-1)\n",
    "        entropy = -torch.sum(target_probs * torch.log(target_probs + 1e-12), dim=-1)\n",
    "\n",
    "        # Normalize the cross-entropy loss by entropy\n",
    "        normalized_loss = ce_loss / (entropy + 1e-12)\n",
    "\n",
    "        if self.reduction == 'mean':\n",
    "            return normalized_loss.mean()\n",
    "        elif self.reduction == 'sum':\n",
    "            return normalized_loss.sum()\n",
    "        else:\n",
    "            return normalized_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be9bd0a-3944-4076-a732-53c321bfae5e",
   "metadata": {},
   "source": [
    "## Normalized Cross Entropy - V2 REVISED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "f981cddd-838e-4cd9-b440-822fcd85b305",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NormalizedCrossEntropyLoss_REVISED(nn.Module):\n",
    "    def __init__(self, reduction='mean'):\n",
    "        super(NormalizedCrossEntropyLoss_REVISED, self).__init__()\n",
    "        self.reduction = reduction\n",
    "        self.cross_entropy = nn.CrossEntropyLoss(reduction='none')  # Keep 'none' for per-sample loss\n",
    "\n",
    "    def forward(self, logits, targets):\n",
    "        # Compute standard cross-entropy loss\n",
    "        ce_loss = self.cross_entropy(logits, targets)\n",
    "        \n",
    "        # Compute the entropy of the target distribution\n",
    "        target_probs = torch.softmax(logits, dim=-1)\n",
    "        entropy = -torch.sum(target_probs * torch.log(target_probs + 1e-12), dim=-1)\n",
    "\n",
    "        # Normalize the cross-entropy loss by entropy\n",
    "        normalized_loss = ce_loss / (entropy + 1e-12)\n",
    "\n",
    "        # Apply reduction\n",
    "        if self.reduction == 'mean':\n",
    "            return normalized_loss.mean()  # Scalar\n",
    "        elif self.reduction == 'sum':\n",
    "            return normalized_loss.sum()  # Scalar\n",
    "        else:\n",
    "            return normalized_loss  # No reduction, returns a tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "795542ef-1e5a-46f4-9be7-8e876cf7b984",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "classes = train_data_noise.classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c736ac-cacd-46a2-829c-cf2cfc745823",
   "metadata": {},
   "source": [
    "## Dataloaders && Batch Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "9dfd694a-b312-4429-97ff-68e5c74ba989",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(195, 39)"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BATCH_SIZE = 256\n",
    "\n",
    "train_data_loader = DataLoader(\n",
    "    train_data_noise, \n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    drop_last=True\n",
    ")\n",
    "\n",
    "test_data_loader = DataLoader(\n",
    "    test_dataset, \n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    drop_last=True\n",
    ")\n",
    "\n",
    "len(train_data_loader), len(test_data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "a3732a04-67cd-4f69-9b80-79eefba0ac1e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def show_images_with_labels(data_loader, class_names, num_images=16):\n",
    "    images, labels = next(iter(data_loader))\n",
    "    \n",
    "    grid_size = int(np.sqrt(num_images))\n",
    "    assert grid_size ** 2 == num_images, \"num_images must be a perfect square.\"\n",
    "    \n",
    "    images = images.permute(0, 2, 3, 1).numpy()  # Convert to (batch_size, height, width, channels)\n",
    "    images = (images * 0.5) + 0.5  # Assuming images were normalized to [-1, 1]\n",
    "    \n",
    "    # Create a grid of subplots\n",
    "    fig, axes = plt.subplots(grid_size, grid_size, figsize=(8, 8))\n",
    "    fig.suptitle(\"Images and Labels\", fontsize=16)\n",
    "    \n",
    "    for i, ax in enumerate(axes.flatten()):\n",
    "        if i >= num_images:\n",
    "            break\n",
    "        ax.imshow(images[i])\n",
    "        ax.axis(\"off\") \n",
    "        ax.set_title(class_names[labels[i].item()], fontsize=10, color=\"black\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# show_images_with_labels(train_data_loader, classes, num_images=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2312a65b-e38e-47c0-9a5a-9f63692481be",
   "metadata": {},
   "source": [
    "## Model - V1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "60663117-c0db-4c15-b4c8-1481fdff4f4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nmodel = CNN_V1(\\n    input_shape=3, #3 color channels\\n    hidden_units=32,\\n    output_shape=len(classes)\\n)\\nmodel\\n'"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "class CNN_V1(nn.Module):\n",
    "    def __init__(self, input_shape, hidden_units, output_shape):\n",
    "        super().__init__()\n",
    "        self.block1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=input_shape, out_channels=hidden_units, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=hidden_units, out_channels=hidden_units, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)  # Reduces 32x32 -> 16x16\n",
    "        )\n",
    "        self.block2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=hidden_units, out_channels=hidden_units * 2, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=hidden_units * 2, out_channels=hidden_units * 2, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)  # Reduces 16x16 -> 8x8\n",
    "        )\n",
    "        self.block3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=hidden_units * 2, out_channels=hidden_units * 4, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=hidden_units * 4, out_channels=hidden_units * 4, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)  # Reduces 8x8 -> 4x4\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=hidden_units * 4 * 4 * 4, out_features=256),  # Flattened size: 4x4x(hidden_units * 4)\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(in_features=256, out_features=output_shape)  # Output size: number of classes\n",
    "        )\n",
    "\n",
    "    def forward(self, x, print_dims=False):\n",
    "        y_b1 = self.block1(x)\n",
    "        y_b2 = self.block2(y_b1)\n",
    "        y_b3 = self.block3(y_b2)\n",
    "        y = self.classifier(y_b3)\n",
    "        if print_dims:\n",
    "            print(f\"{y_b1.shape=}\")\n",
    "            print(f\"{y_b2.shape=}\")\n",
    "            print(f\"{y_b3.shape=}\")\n",
    "            print(f\"{y.shape=}\")\n",
    "        return y\n",
    "\"\"\"\n",
    "model = CNN_V1(\n",
    "    input_shape=3, #3 color channels\n",
    "    hidden_units=32,\n",
    "    output_shape=len(classes)\n",
    ")\n",
    "model\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f796ab6b-d0e1-4e5d-8f72-1b63cec9809b",
   "metadata": {},
   "source": [
    "## Model - V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "a7eeb3f1-2c52-4caf-8953-15ecb8a42d91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleCNN(\n",
       "  (conv_layers): Sequential(\n",
       "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU()\n",
       "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (7): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (9): ReLU()\n",
       "    (10): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (12): ReLU()\n",
       "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (14): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (16): ReLU()\n",
       "    (17): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (19): ReLU()\n",
       "    (20): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (fc_layers): Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1)\n",
       "    (1): Linear(in_features=2048, out_features=256, bias=True)\n",
       "    (2): ReLU()\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): Linear(in_features=256, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        \n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),  # 32x32 -> 16x16\n",
    "\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),  # 16x16 -> 8x8\n",
    "\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2)  # 8x8 -> 4x4\n",
    "        )\n",
    "\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128 * 4 * 4, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = self.fc_layers(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "model = SimpleCNN(num_classes=num_classes)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd04a7b-9143-4540-b6a1-f7f7255b58ca",
   "metadata": {},
   "source": [
    "## Loss Function & Optimizer - V1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "13051435-9b32-4a91-92f2-90f05885c8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss_fn_cnn = NormalizedCrossEntropyLoss_REVISED(model)\n",
    "# loss_fn_cnn = nn.CrossEntropyLoss()\n",
    "# optimizer = torch.optim.AdamW(model.parameters(), lr=0.001, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec86e9fe-941d-4013-a0e1-9ee90f4e2918",
   "metadata": {},
   "source": [
    "## Loss Function & Optimizer - V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "4e2f04a1-41e8-4ed1-8bde-7fd6ff22361b",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=1e-3)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)  # Reduce LR every 10 epochs\n",
    "criterion = NormalizedCrossEntropyLoss_REVISED(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8f5691-4c3b-4472-8291-85bdb82f12a4",
   "metadata": {},
   "source": [
    "## Loss Function & Optimizer - V3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "0084995a-81a1-4c9f-b46e-53598ce8a8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer = torch.optim.AdamW(\n",
    "#     model.parameters(),  # Ensure `model` is defined\n",
    "#     lr=0.001,            # Initial learning rate\n",
    "#     betas=(0.9, 0.999),  # Default values for AdamW\n",
    "#     eps=1e-8,            # Small epsilon value for numerical stability\n",
    "#     weight_decay=0.01    # L2 regularization strength\n",
    "# )\n",
    "# scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200, eta_min=1e-6)\n",
    "# criterion = NormalizedCrossEntropyLoss_REVISED(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "ca7be47b-adef-4746-941f-6cf3930f6db8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(NormalizedCrossEntropyLoss_REVISED(\n",
       "   (reduction): SimpleCNN(\n",
       "     (conv_layers): Sequential(\n",
       "       (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "       (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (2): ReLU()\n",
       "       (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "       (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (5): ReLU()\n",
       "       (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "       (7): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "       (8): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (9): ReLU()\n",
       "       (10): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "       (11): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (12): ReLU()\n",
       "       (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "       (14): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "       (15): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (16): ReLU()\n",
       "       (17): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "       (18): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (19): ReLU()\n",
       "       (20): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "     )\n",
       "     (fc_layers): Sequential(\n",
       "       (0): Flatten(start_dim=1, end_dim=-1)\n",
       "       (1): Linear(in_features=2048, out_features=256, bias=True)\n",
       "       (2): ReLU()\n",
       "       (3): Dropout(p=0.5, inplace=False)\n",
       "       (4): Linear(in_features=256, out_features=10, bias=True)\n",
       "     )\n",
       "   )\n",
       "   (cross_entropy): CrossEntropyLoss()\n",
       " ),\n",
       " SGD (\n",
       " Parameter Group 0\n",
       "     dampening: 0\n",
       "     differentiable: False\n",
       "     foreach: None\n",
       "     fused: None\n",
       "     initial_lr: 0.01\n",
       "     lr: 0.01\n",
       "     maximize: False\n",
       "     momentum: 0.9\n",
       "     nesterov: False\n",
       "     weight_decay: 0.001\n",
       " ),\n",
       " <torch.optim.lr_scheduler.StepLR at 0x28d1fdb9510>)"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion, optimizer, scheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb8b2e9f-ed33-4203-9bbc-50669c0a3d0d",
   "metadata": {},
   "source": [
    "## Test Accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "3cf50221-84ab-45a7-864c-c42fa09491bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, dataloader, loss_fn, device='cuda'):\n",
    "    model.to(device)\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    running_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient computation for efficiency\n",
    "        for images, labels in dataloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            loss = loss.mean() if loss.dim() > 0 else loss\n",
    "\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    test_loss = running_loss / total\n",
    "    test_acc = correct / total\n",
    "\n",
    "    \n",
    "    model.train()\n",
    "    return test_loss, test_acc\n",
    "    \n",
    "# test_loss, test_acc = evaluate_model(model, test_data_loader, device=DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f4f9322-0cb1-421d-a7e9-8bf1ab6b168a",
   "metadata": {},
   "source": [
    "## Train Loop - V1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "18b6fd9c-3214-4755-83be-ebb97f800ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloader, optimizer, loss_fn, num_epochs=10, device='cuda'):\n",
    "    model.to(device)\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        \n",
    "        for images, labels in dataloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            # print(\"Logits range:\", outputs.min().item(), outputs.max().item())\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            loss = loss.mean() if loss.dim() > 0 else loss\n",
    "            # print(f\"Loss shape: {loss.shape}\")\n",
    "\n",
    "            \n",
    "            # Backward pass\n",
    "            model.train()\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Statistics\n",
    "            #ADD Testaccruracy\n",
    "            \n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        epoch_loss = running_loss / total\n",
    "        epoch_acc = correct / total\n",
    "        test_loss, test_acc = evaluate_model(model, test_data_loader, device=DEVICE)\n",
    "        test_loss, test_acc = 0,0\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs} | Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.4f} | Test Loss: {test_loss:.4f}, Test Accuracy: {test_acc:.4f}\") \n",
    "\n",
    "# Train the model\n",
    "# train_model(model, train_data_loader, optimizer, loss_fn=loss_fn_cnn, num_epochs=10, device=DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f05fdfc-d858-4dda-a100-49b3bf3e0898",
   "metadata": {},
   "source": [
    "### Termination flag checker and logger for remote logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "52f0d73c-c21a-4dfa-ac00-aaa6999d1ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_termination_flag(file_path=\"TFlag.txt\"):\n",
    "    try:\n",
    "        with open(file_path, 'r') as file:  # Open the file in read mode\n",
    "            content = file.read().strip()  # Read the content and remove any extra whitespace\n",
    "            if content == '0':\n",
    "                print(\"Received Termination Signal. Terminating...\")\n",
    "                return True  # Terminate the loop\n",
    "            elif content == '1':\n",
    "                return False  # Continue the loop\n",
    "            else:\n",
    "                print(f\"Unexpected content in file: {content}. Expected '0' or '1'. Terminating Process...\")\n",
    "                return True  # Continue the loop by default\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not found: {file_path}\")\n",
    "        return False  # Continue the loop if the file doesn't exist\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {e}. Terminating Process...\")\n",
    "        return True  # Continue the loop in case of other errors|\n",
    "def log(message):\n",
    "    tracker = IntegerTracker()\n",
    "    path = f\"Logs\\\\Log_{tracker.read_value()}.txt\"\n",
    "    with open(path, \"a\") as f:\n",
    "        f.write(f\"{time.strftime('%Y-%m-%d %H:%M:%S')} - {message}\\n\")\n",
    "\n",
    "arch = [criterion.state_dict, optimizer.state_dict, scheduler.state_dict()]\n",
    "for i in arch:\n",
    "    log(i)\n",
    "    log('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4053e6a7-cf56-477e-9e23-59e6b1ba5f26",
   "metadata": {},
   "source": [
    "## Train Loop - V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad5343f-b064-441d-94dc-58321d6d5640",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100 | Train Loss: 0.9514, Train Accuracy: 0.2709 | Test Loss: 0.8387, Test Accuracy: 0.4757 | Time Stamp: 23.511 s\n",
      "Epoch 2/100 | Train Loss: 0.9199, Train Accuracy: 0.3474 | Test Loss: 0.8125, Test Accuracy: 0.5234 | Time Stamp: 48.207 s\n",
      "Epoch 3/100 | Train Loss: 0.9061, Train Accuracy: 0.3809 | Test Loss: 0.7994, Test Accuracy: 0.5443 | Time Stamp: 72.969 s\n",
      "Epoch 4/100 | Train Loss: 0.8963, Train Accuracy: 0.4059 | Test Loss: 0.7789, Test Accuracy: 0.5681 | Time Stamp: 97.657 s\n",
      "Epoch 5/100 | Train Loss: 0.8877, Train Accuracy: 0.4249 | Test Loss: 0.7664, Test Accuracy: 0.6076 | Time Stamp: 122.398 s\n",
      "Epoch 6/100 | Train Loss: 0.8805, Train Accuracy: 0.4416 | Test Loss: 0.7543, Test Accuracy: 0.6423 | Time Stamp: 147.192 s\n",
      "Epoch 7/100 | Train Loss: 0.8738, Train Accuracy: 0.4561 | Test Loss: 0.7498, Test Accuracy: 0.6447 | Time Stamp: 172.000 s\n",
      "Epoch 8/100 | Train Loss: 0.8687, Train Accuracy: 0.4665 | Test Loss: 0.7425, Test Accuracy: 0.6682 | Time Stamp: 196.764 s\n",
      "Epoch 9/100 | Train Loss: 0.8629, Train Accuracy: 0.4780 | Test Loss: 0.7237, Test Accuracy: 0.6894 | Time Stamp: 221.535 s\n",
      "Epoch 10/100 | Train Loss: 0.8606, Train Accuracy: 0.4855 | Test Loss: 0.7351, Test Accuracy: 0.6589 | Time Stamp: 246.214 s\n",
      "Epoch 11/100 | Train Loss: 0.8499, Train Accuracy: 0.5002 | Test Loss: 0.7040, Test Accuracy: 0.6966 | Time Stamp: 271.014 s\n",
      "Epoch 12/100 | Train Loss: 0.8456, Train Accuracy: 0.5095 | Test Loss: 0.7029, Test Accuracy: 0.6994 | Time Stamp: 295.732 s\n",
      "Epoch 13/100 | Train Loss: 0.8444, Train Accuracy: 0.5117 | Test Loss: 0.6997, Test Accuracy: 0.7195 | Time Stamp: 320.477 s\n",
      "Epoch 14/100 | Train Loss: 0.8415, Train Accuracy: 0.5141 | Test Loss: 0.7076, Test Accuracy: 0.7117 | Time Stamp: 345.188 s\n",
      "Epoch 15/100 | Train Loss: 0.8397, Train Accuracy: 0.5220 | Test Loss: 0.7017, Test Accuracy: 0.6942 | Time Stamp: 370.018 s\n",
      "Epoch 16/100 | Train Loss: 0.8381, Train Accuracy: 0.5218 | Test Loss: 0.6924, Test Accuracy: 0.7246 | Time Stamp: 394.816 s\n",
      "Epoch 17/100 | Train Loss: 0.8361, Train Accuracy: 0.5250 | Test Loss: 0.6824, Test Accuracy: 0.7278 | Time Stamp: 419.444 s\n",
      "Epoch 18/100 | Train Loss: 0.8341, Train Accuracy: 0.5287 | Test Loss: 0.6900, Test Accuracy: 0.7291 | Time Stamp: 444.102 s\n",
      "Epoch 19/100 | Train Loss: 0.8319, Train Accuracy: 0.5336 | Test Loss: 0.6846, Test Accuracy: 0.7199 | Time Stamp: 468.884 s\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "INCLUDE_TEST = True\n",
    "\n",
    "num_epochs = 100  # Train for more epochs\n",
    "\n",
    "train_losses, train_accuracies, test_losses, test_accuracies = torch.Tensor(num_epochs), torch.Tensor(num_epochs), torch.Tensor(num_epochs), torch.Tensor(num_epochs)\n",
    "\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "for epoch in range(num_epochs):\n",
    "    if check_termination_flag():\n",
    "        log(\"Termination Train Loop (Manual)\")\n",
    "        break\n",
    "    model.train()\n",
    "    total_loss, correct, total = 0, 0, 0\n",
    "    \n",
    "    for images, labels in train_data_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss = loss.mean() if loss.dim() > 0 else loss\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        _, preds = outputs.max(1)\n",
    "        correct += preds.eq(labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    #Test Accuracy:\n",
    "    test_loss, test_acc = 0,0\n",
    "    if INCLUDE_TEST:\n",
    "        model.eval()\n",
    "        test_loss, test_acc = evaluate_model(model, test_data_loader, criterion, device=DEVICE)\n",
    "        model.train()\n",
    "    test_losses[epoch] = test_loss\n",
    "    test_accuracies[epoch] = test_acc\n",
    "    \n",
    "    scheduler.step()  # Adjust LR\n",
    "    \n",
    "\n",
    "    \n",
    "    train_loss = total_loss/len(train_data_loader)\n",
    "    train_accuracy = correct/total\n",
    "    train_losses[epoch] = train_loss\n",
    "    train_accuracies[epoch] = train_accuracy\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} | Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f} | Test Loss: {test_loss:.4f}, Test Accuracy: {test_acc:.4f} | Time Stamp: {(time.time()-start_time):.3f} s\")\n",
    "    log(f\"Epoch {epoch+1}/{num_epochs} | Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f} | Test Loss: {test_loss:.4f}, Test Accuracy: {test_acc:.4f}\")\n",
    "end_time = time.time()\n",
    "train_time = end_time-start_time\n",
    "print(f\"Train Time : {train_time:.6f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61bcb05e-3cd8-40d7-97ec-a4cd2d222392",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def LogLossesAndAccuracy(metrics, arch, info):\n",
    "    try:\n",
    "        tracker = IntegerTracker()\n",
    "        path = f\"Logs\\\\Log_{tracker.read_value()}.txt\"\n",
    "        with open(path, \"a\") as f:\n",
    "            \n",
    "            for i in arch:\n",
    "                f.write(f\"{i}\\n\\n\")\n",
    "            # for values,msg in zip(metrics,msgs):\n",
    "            #     for i in range(values.shape[0]):\n",
    "            #         f.write(f\"Epoch {i+1} | {msg}: {values[i]:.4f}\\n\")\n",
    "            \n",
    "            f.write(f\"\\nKey Info:\\n{info}\\n\\n\")\n",
    "            \n",
    "            # for i in range(len(accuracies)):\n",
    "            #     f.write(f\"Epoch {i+1} | Loss: {losses[i]:.4f} | Accuracy: {accuracies[i]:.4f}\\n\")\n",
    "            length = len(metrics[next(iter(metrics))])\n",
    "            for i in range(length):\n",
    "                metric_msg = \"\"\n",
    "                metric_msg += f\"\\nEpoch {i} | \"\n",
    "                for metric_name, values in metrics.items():\n",
    "                    metric_msg += f\"{metric_name}: {values[i]:.4f}\"\n",
    "                    metric_msg += \" | \" if metric_name!=list(metrics.keys())[-1] else \"\"\n",
    "                f.write(f\"{metric_msg}\")\n",
    "                \n",
    "        print(f\"Logged File | {path = }\")\n",
    "        tracker.increment_value()\n",
    "    except FileExistsError:\n",
    "        print(\"Already exists.\")\n",
    "    \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce0dbe2-d15d-41f5-a557-21325eefdf12",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = {\n",
    "    \"Train Accuracy\":train_accuracies,\n",
    "    \"Train Loss\":train_losses,\n",
    "    \"Test Loss\":test_losses,\n",
    "    \"Test Accuracy\":test_accuracies\n",
    "}\n",
    "info = f\"Noise Rate: {train_data_noise.noise_rate:.4f} \\nTrain Time: {train_time:.6f}s \\nTransforms: HOR_FLIP ROT_10 NORM \\nLoss({criterion.__class__}) \\nOptimizer({optimizer.__class__}) \\nScheduler({scheduler.__class__})\"\n",
    "# LogLossesAndAccuracy(metrics, arch = [criterion.state_dict, optimizer.state_dict, scheduler.state_dict()], info=info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9fc142f-b900-4c81-9006-17ec3c65fd14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metrics(metrics):\n",
    "    \"\"\"\n",
    "    Plots all arrays in the dictionary on the same graph.\n",
    "    \n",
    "    :param metrics: A dictionary where keys are strings (metric names) and values are arrays (metric values).\n",
    "    \"\"\"\n",
    "    # Create a figure and axis\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    # Iterate over the dictionary and plot each array\n",
    "    for metric_name, values in metrics.items():\n",
    "        x_values = range(len(values))  # Use indices as the x-axis\n",
    "        plt.plot(x_values, values, linestyle='-', label=metric_name)\n",
    "    \n",
    "    # Add labels and title\n",
    "    plt.xlabel('Index')\n",
    "    plt.ylabel('Value')\n",
    "    plt.title('Metrics')\n",
    "    \n",
    "    # Add a legend\n",
    "    plt.legend()\n",
    "    \n",
    "    # Show the plot\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9283ed96-7090-47c1-8e91-730f760784b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plot_metrics(metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d535ebe-5bc3-4341-99d4-7f1fd1279eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tracker = IntegerTracker()\n",
    "\n",
    "torch.save({\n",
    "    'model_state_dict':model.state_dict(),\n",
    "    'optimizer_state_dict':optimizer.state_dict(),\n",
    "    'criterion_state_dict':criterion.state_dict(),\n",
    "    'scheduler_state_dict':scheduler.state_dict(),\n",
    "    'metrics':metrics\n",
    "}, f'Models\\\\cnn_{tracker.read_value()-1}.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612dd8de-31ee-4099-9dae-a78dbfd565b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tracker = IntegerTracker()\n",
    "tracker.increment_value()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4143ed9d-95d4-4d1a-a50f-c6caede8f482",
   "metadata": {},
   "outputs": [],
   "source": [
    "tracker.read_value()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd6793a-e560-4d0f-9ec5-6672c805dc22",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-ml_stuff]",
   "language": "python",
   "name": "conda-env-.conda-ml_stuff-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
